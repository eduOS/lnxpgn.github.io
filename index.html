<!doctype html>
<html class="theme-next use-motion theme-next-mist">
<head>
  

<meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>






  <link rel="stylesheet" type="text/css" href="/vendors/fancybox/source/jquery.fancybox.css?v=2.1.5"/>


<link rel="stylesheet" type="text/css" href="/css/main.css?v=0.4.3"/>


    <meta name="description" content="lnxpgn's tech blog" />



  <meta name="keywords" content="Hexo,next" />



  <link rel="alternate" href="/atom.xml" title="竹里馆" type="application/atom+xml" />



  <link rel="shorticon icon" type="image/x-icon" href="/favicon.ico?v=0.4.3" />



<script type="text/javascript" id="hexo.configuration">
  var CONFIG = {
    scheme: 'Mist',
    analytics: {
      google: ''
    },
    sidebar: 'post'
  };
</script>




  <title> 竹里馆 </title>
</head>

<body>
  <!--[if lte IE 8]>
  <div style=' clear: both; height: 59px; padding:0 0 0 15px; position: relative;margin:0 auto;'>
    <a href="http://windows.microsoft.com/en-US/internet-explorer/products/ie/home?ocid=ie6_countdown_bannercode">
      <img src="http://7u2nvr.com1.z0.glb.clouddn.com/picouterie.jpg" border="0" height="42" width="820"
           alt="You are using an outdated browser. For a faster, safer browsing experience, upgrade for free today or use other browser ,like chrome firefox safari."
           style='margin-left:auto;margin-right:auto;display: block;'/>
    </a>
  </div>
<![endif]-->

  <div class="container one-column 
   page-home 
">
    <div class="headband"></div>

    <div id="header" class="header">
      <div class="header-inner">
        <h1 class="site-meta">
  <span class="logo-line-before"><i></i></span>
  <a href="/" class="brand">
      <span class="logo">
        <i class="icon-logo"></i>
      </span>
      <span class="site-title">竹里馆</span>
  </a>
  <span class="logo-line-after"><i></i></span>
</h1>

<div class="site-nav-toggle">
  <button>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
  </button>
</div>

<div class="site-nav">
  

  
    <ul id="menu" class="menu ">
      
        
        <li class="menu-item menu-item-home">
          <a href="/">
            <i class="menu-item-icon icon-home"></i> <br />
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about">
            <i class="menu-item-icon icon-about"></i> <br />
            About
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives">
            <i class="menu-item-icon icon-archives"></i> <br />
            Archives
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags">
            <i class="menu-item-icon icon-tags"></i> <br />
            Tags
          </a>
        </li>
      
    </ul>
  

  
</div>


      </div>
    </div>

    <div id="main" class="main">
      <div class="main-inner">
        <div id="content" class="content">
          
  <div id="posts" class="posts-expand">
    
      

  <div class="post post-type-normal ">
    <div class="post-header">

      
      
        <h1 class="post-title">
          
          
            
              <a class="post-title-link" href="/2015/07/27/using-multiple-spiders-in-a-scrapy-project/">
                Using multiple spiders in a Scrapy project
              </a>
            
          
        </h1>
      

      <div class="post-meta">
        <span class="post-time">
          Posted on 2015-07-27
        </span>

        

        
          
        
      </div>
    </div>

    <div class="post-body">

      
      

      
        
          <h2>Overview</h2>
<p>Different channel's structure in a websit are similar, sometimes we want to reuse source code and don't create a <a href="http://scrapy.org/" target="_blank" rel="external">Scrap</a> project per channel. This is a tutorial how to use multiple spiders in a Scrapy project.</p>
<h2>ENV</h2>
<p>Python: 2.7.5<br>
Scrapy: 0.24.2</p>
<h2>Tree-like directories of this tutorial project</h2>
<p>Source code in GitHub: <a href="http://xxx.com" target="_blank" rel="external">http://xxx.com</a></p>
<figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">scrapy_multiple_spiders</span><br><span class="line">├── commands</span><br><span class="line">│   ├── __init__<span class="class">.py</span></span><br><span class="line">│   └── crawl<span class="class">.py</span></span><br><span class="line">└── tutorial</span><br><span class="line">    ├── scrapy<span class="class">.cfg</span></span><br><span class="line">    └── tutorial</span><br><span class="line">        ├── __init__<span class="class">.py</span></span><br><span class="line">        ├── common_spider<span class="class">.py</span></span><br><span class="line">        ├── items<span class="class">.py</span></span><br><span class="line">        ├── pipelines<span class="class">.py</span></span><br><span class="line">        ├── settings<span class="class">.py</span></span><br><span class="line">        ├── spider_settings</span><br><span class="line">        │   ├── __init__<span class="class">.py</span></span><br><span class="line">        │   ├── spider1<span class="class">.py</span></span><br><span class="line">        │   └── spider2<span class="class">.py</span></span><br><span class="line">        └── spiders</span><br><span class="line">            ├── __init__<span class="class">.py</span></span><br><span class="line">            ├── spider1<span class="class">.py</span></span><br><span class="line">            └── spider2.py</span><br></pre></td></tr></table></figure>
<!-- mo-re -->
<h2>Custom project command</h2>
<p>In Scrapy we can add our custom project commands by using the COMMANDS_MODULE setting item in <em>settings.py</em>, we will custom the standard <em>&quot;crawl&quot;</em> command. When call <em>&quot;scrapy crawl &lt;spider name&gt;&quot;</em>, the <em>run()</em> function in <em>scrapy.commands.crawl.Command</em> is the entrance. Inherit <em>scrapy.commands.crawl.Command</em> and overwrite the <em>run()</em> function in our project's <em>commands.crawl.CustomCrawlCommand</em> class.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CustomCrawlCommand</span><span class="params">(Command)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">run</span><span class="params">(self, args, opts)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> len(args) &lt; <span class="number">1</span>:</span><br><span class="line">            <span class="keyword">raise</span> UsageError()</span><br><span class="line">        <span class="keyword">elif</span> len(args) &gt; <span class="number">1</span>:</span><br><span class="line">            <span class="keyword">raise</span> UsageError(<span class="string">"running 'scrapy crawl' with more than one spider is no longer supported"</span>)</span><br><span class="line">        spname = args[<span class="number">0</span>]</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># added new code</span></span><br><span class="line">        spider_settings_path = self.settings.getdict(<span class="string">'SPIDER_SETTINGS'</span>, &#123;&#125;).get(spname, <span class="keyword">None</span>)</span><br><span class="line">        <span class="keyword">if</span> spider_settings_path <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>:</span><br><span class="line">            self.settings.setmodule(spider_settings_path, priority=<span class="string">'cmdline'</span>)</span><br><span class="line">        <span class="comment"># end</span></span><br><span class="line">                 </span><br><span class="line">        crawler = self.crawler_process.create_crawler()</span><br><span class="line">        spider = crawler.spiders.create(spname, **opts.spargs)</span><br><span class="line">        crawler.crawl(spider)</span><br><span class="line">        self.crawler_process.start()</span><br></pre></td></tr></table></figure>
<p>The commented part is new code, others are same as <em>scrapy.commands.crawl.Command.run()</em>. The Scrapy <em>settings</em> has four priorities: <em>default, command, project, cmdline</em>, the <em>cmdline</em> has a top priority, use it to overwrite default setting items which are in <em>settings.py</em>. <em>&quot;SPIDER_SETTINGS&quot;</em> is a setting item in settings.py, it is a directory including spiders' custom setting files.</p>
<h2>Create common spiders and settings</h2>
<p><em>tutorial.tutorial.common_spider.CommonSpider</em> is a spider which includes a normal parsing process for a website and some common functions. <em>settings.py</em> includes common setting items for all spiders, such as <em>LOG_LEVEL</em>, you can overwrite them in a spider custom setting file, such as <em>spider1.py</em> and <em>spider2.py</em> in <em>tutorial.tutorial.spider_settings</em> directory.</p>
<p>common_spider.py</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CommonSpider</span><span class="params">(Spider)</span>:</span></span><br><span class="line">    <span class="string">"""</span><br><span class="line">        This is a common spider, including common functions which child spiders can inherit or overwrite</span><br><span class="line">    """</span></span><br><span class="line">    name = <span class="string">''</span></span><br><span class="line">    allowed_domains = []</span><br><span class="line">    start_urls = []</span><br><span class="line"></span><br><span class="line">    <span class="comment"># must add "kwargs", otherwise can't run in scrapyd</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, settings, **kwargs)</span>:</span></span><br><span class="line">        super(CommonSpider, self).__init__(**kwargs)</span><br><span class="line"></span><br><span class="line">        self._start_urls = []</span><br><span class="line">        self._start_urls.extend(settings.get(<span class="string">'START_URLS'</span>, []))</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> self._start_urls:</span><br><span class="line">            <span class="keyword">raise</span> Exception(<span class="string">'no urls to crawl'</span>)</span><br><span class="line"></span><br><span class="line">    <span class="decorator">@classmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">from_settings</span><span class="params">(cls, settings, **kwargs)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> cls(settings, **kwargs)</span><br><span class="line"></span><br><span class="line">    <span class="decorator">@classmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">from_crawler</span><span class="params">(cls, crawler, **kwargs)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> cls.from_settings(crawler.settings, **kwargs)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">start_requests</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">for</span> url <span class="keyword">in</span> self._start_urls:</span><br><span class="line">            <span class="comment"># must append these hosts, otherwise OffsiteMiddleware will filter them</span></span><br><span class="line">            parsed_url = urlparse.urlparse(url)</span><br><span class="line">            parsed_url.hostname <span class="keyword">and</span> self.allowed_domains.append(parsed_url.hostname)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># open('file name', 'a+') is different between OS X and Linux, </span></span><br><span class="line">            <span class="comment"># read an empty filter list from &lt;JOBDIR&gt;/requests.seen when launche the spider on OS X, </span></span><br><span class="line">            <span class="comment"># be careful "dont_filter"</span></span><br><span class="line">            <span class="keyword">yield</span> Request(url, callback=self.parse, method=<span class="string">'GET'</span>, dont_filter=<span class="keyword">True</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span><span class="params">(self, response)</span>:</span></span><br><span class="line">        self.log(<span class="string">'response url: %s, status: %d'</span> % (response.url, response.status), INFO)</span><br></pre></td></tr></table></figure>
<p>settings.py</p>
<figure class="highlight ocaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">COMMANDS_MODULE</span> = <span class="symbol">'commands'</span></span><br><span class="line"></span><br><span class="line"><span class="type">SPIDER_SETTINGS</span> = &#123;</span><br><span class="line">    <span class="symbol">'spider1'</span>: <span class="symbol">'tutorial</span>.spider_settings.spider1',</span><br><span class="line">    <span class="symbol">'spider2'</span>: <span class="symbol">'tutorial</span>.spider_settings.spider2',</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">LOG_LEVEL</span> = <span class="symbol">'INFO'</span></span><br></pre></td></tr></table></figure>
<h2>Create multiple spiders in a project</h2>
<h3>spider without custom parsing process</h3>
<p>like <em>tutorial.tutorial.spiders.spider1.Spider1</em><br>
Spider1's setting file: spider1.py (in <em>&quot;spider_settings&quot;</em> directory)</p>
<figure class="highlight nginx"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="title">LOG_FILE</span> = <span class="string">'spider1.log'</span></span><br><span class="line"></span><br><span class="line">JOBDIR=<span class="string">'spider1_job'</span></span><br><span class="line"></span><br><span class="line">START_URLS = [<span class="string">'http://www.bing.com/news'</span>]</span><br></pre></td></tr></table></figure>
<p>Spider1's source file: Spider1.py (in <em>&quot;spiders&quot;</em> directory)</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> ..common_spider <span class="keyword">import</span> CommonSpider</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Spider1</span><span class="params">(CommonSpider)</span>:</span></span><br><span class="line">    name = <span class="string">'spider1'</span></span><br></pre></td></tr></table></figure>
<h3>spider with custom parsing process</h3>
<p>like <em>tutorial.tutorial.spiders.spider2.Spider2</em><br>
Spider2's setting file: spider2.py (in <em>&quot;spider_settings&quot;</em> directory)</p>
<figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">LOG_FILE = <span class="string">'spider2</span>.log'</span><br><span class="line"></span><br><span class="line">JOBDIR=<span class="string">'spider2_job</span>'</span><br><span class="line"></span><br><span class="line">START_URLS = [<span class="string">'http</span>:<span class="comment">//www.bing.com/knows']</span></span><br><span class="line"></span><br><span class="line">TITLE_PATH = <span class="string">'html</span> head title::text'</span><br></pre></td></tr></table></figure>
<p>Spider2's source file: Spider2.py (in <em>&quot;spiders&quot;</em> directory)</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> scrapy.log <span class="keyword">import</span> INFO</span><br><span class="line"><span class="keyword">from</span> ..common_spider <span class="keyword">import</span> CommonSpider</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Spider2</span><span class="params">(CommonSpider)</span>:</span></span><br><span class="line">    name = <span class="string">'spider2'</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># must add "kwargs", otherwise can't run in scrapyd</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, settings, **kwargs)</span>:</span></span><br><span class="line">        super(Spider2, self).__init__(settings, **kwargs)</span><br><span class="line"></span><br><span class="line">        self._title_path = settings.get(<span class="string">'TITLE_PATH'</span>, <span class="string">''</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse_other_info</span><span class="params">(self, response)</span>:</span></span><br><span class="line">        title = response.css(self._title_path).extract()[<span class="number">0</span>]</span><br><span class="line">        self.log(<span class="string">'title: %s'</span> % title, INFO)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span><span class="params">(self, response)</span>:</span></span><br><span class="line">        self.parse_other_info(response)</span><br><span class="line"></span><br><span class="line">        super(Spider2, self).parse(response)</span><br></pre></td></tr></table></figure>
<h2>Run spiders</h2>
<ol>
<li>set <em>PYTHONPATH</em> to <em>&quot;/&lt;path&gt;/scrapy_multiple_spiders&quot;</em></li>
<li>in <em>&quot;/&lt;path&gt;/scrapy_multiple_spiders/tutorial&quot;</em>, call <em>scrapy crawl spider1</em> or <em>scrapy crawl spider2</em>, check log file <em>spider1.log</em> or <em>spider2.log</em></li>
</ol>

        
      
    </div>

    <div class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </div>
  </div>


    
      

  <div class="post post-type-normal ">
    <div class="post-header">

      
      
        <h1 class="post-title">
          
          
            
              <a class="post-title-link" href="/2015/07/27/using-multiple-spiders-in-a-scrapy-project2/">
                Using multiple spiders in a Scrapy project
              </a>
            
          
        </h1>
      

      <div class="post-meta">
        <span class="post-time">
          Posted on 2015-07-27
        </span>

        

        
          
        
      </div>
    </div>

    <div class="post-body">

      
      

      
        
          <h2>Overview</h2>
<p>Different channel's structure in a websit are similar, sometimes we want to reuse source code and don't create a <a href="http://scrapy.org/">Scrap</a> project per channel. This is a tutorial how to use multiple spiders in a Scrapy project.</p>
<h2>ENV</h2>
<p>Python: 2.7.5<br>
Scrapy: 0.24.2
中国</p>
<h2>Tree-like directories of this tutorial project</h2>
<p>Source code in GitHub: <a href="http://xxx.com">http://xxx.com</a></p>
<figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">scrapy_multiple_spiders</span><br><span class="line">├── commands</span><br><span class="line">│   ├── __init__<span class="class">.py</span></span><br><span class="line">│   └── crawl<span class="class">.py</span></span><br><span class="line">└── tutorial</span><br><span class="line">    ├── scrapy<span class="class">.cfg</span></span><br><span class="line">    └── tutorial</span><br><span class="line">        ├── __init__<span class="class">.py</span></span><br><span class="line">        ├── common_spider<span class="class">.py</span></span><br><span class="line">        ├── items<span class="class">.py</span></span><br><span class="line">        ├── pipelines<span class="class">.py</span></span><br><span class="line">        ├── settings<span class="class">.py</span></span><br><span class="line">        ├── spider_settings</span><br><span class="line">        │   ├── __init__<span class="class">.py</span></span><br><span class="line">        │   ├── spider1<span class="class">.py</span></span><br><span class="line">        │   └── spider2<span class="class">.py</span></span><br><span class="line">        └── spiders</span><br><span class="line">            ├── __init__<span class="class">.py</span></span><br><span class="line">            ├── spider1<span class="class">.py</span></span><br><span class="line">            └── spider2.py</span><br></pre></td></tr></table></figure>
<h2>Custom project command</h2>
<p>In Scrapy we can add our custom project commands by using the COMMANDS_MODULE setting item in <em>settings.py</em>, we will custom the standard <em>&quot;crawl&quot;</em> command. When call <em>&quot;scrapy crawl &lt;spider name&gt;&quot;</em>, the <em>run()</em> function in <em>scrapy.commands.crawl.Command</em> is the entrance. Inherit <em>scrapy.commands.crawl.Command</em> and overwrite the <em>run()</em> function in our project's <em>commands.crawl.CustomCrawlCommand</em> class.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CustomCrawlCommand</span><span class="params">(Command)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">run</span><span class="params">(self, args, opts)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> len(args) &lt; <span class="number">1</span>:</span><br><span class="line">            <span class="keyword">raise</span> UsageError()</span><br><span class="line">        <span class="keyword">elif</span> len(args) &gt; <span class="number">1</span>:</span><br><span class="line">            <span class="keyword">raise</span> UsageError(<span class="string">"running 'scrapy crawl' with more than one spider is no longer supported"</span>)</span><br><span class="line">        spname = args[<span class="number">0</span>]</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># added new code</span></span><br><span class="line">        spider_settings_path = self.settings.getdict(<span class="string">'SPIDER_SETTINGS'</span>, &#123;&#125;).get(spname, <span class="keyword">None</span>)</span><br><span class="line">        <span class="keyword">if</span> spider_settings_path <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>:</span><br><span class="line">            self.settings.setmodule(spider_settings_path, priority=<span class="string">'cmdline'</span>)</span><br><span class="line">        <span class="comment"># end</span></span><br><span class="line">                 </span><br><span class="line">        crawler = self.crawler_process.create_crawler()</span><br><span class="line">        spider = crawler.spiders.create(spname, **opts.spargs)</span><br><span class="line">        crawler.crawl(spider)</span><br><span class="line">        self.crawler_process.start()</span><br></pre></td></tr></table></figure>
<p>The commented part is new code, others are same as <em>scrapy.commands.crawl.Command.run()</em>. The Scrapy <em>settings</em> has four priorities: <em>default, command, project, cmdline</em>, the <em>cmdline</em> has a top priority, use it to overwrite default setting items which are in <em>settings.py</em>. <em>&quot;SPIDER_SETTINGS&quot;</em> is a setting item in settings.py, it is a directory including spiders' custom setting files.</p>
          <div class="post-more-link text-center">
            <a class="btn" href="/2015/07/27/using-multiple-spiders-in-a-scrapy-project2/#more">
              Read more &raquo;
            </a>
          </div>
        
      
    </div>

    <div class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </div>
  </div>


    
  </div>

  

        </div>

        
      </div>


      
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <div id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      <div class="site-overview">
        <div class="site-author motion-element">
          <img class="site-author-image" src="/images/default_avatar.jpg" alt="lnxpgn" />
          <p class="site-author-name">lnxpgn</p>
        </div>
        <p class="site-description motion-element">lnxpgn's tech blog</p>
        <div class="site-state motion-element">
          <div class="site-state-item site-state-posts">
            <a href="/archives">
              <span class="site-state-item-count">2</span>
              <span class="site-state-item-name">posts</span>
            </a>
          </div>

          <div class="site-state-item site-state-categories">
            
              <span class="site-state-item-count">0</span>
              <span class="site-state-item-name">categories</span>
              
          </div>

          <div class="site-state-item site-state-tags">
            <a href="/tags">
              <span class="site-state-item-count">4</span>
              <span class="site-state-item-name">tags</span>
              </a>
          </div>

        </div>

        
          <div class="feed-link motion-element">
            <a href="/atom.xml">
              <i class="menu-item-icon icon-feed"></i>
              RSS
            </a>
          </div>
        

        <div class="links-of-author motion-element">
          
        </div>

        
        

      </div>

      

    </div>
  </div>


    </div>

    <div id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">
  
  &copy; &nbsp; 
  2015
  <span class="with-love">
    <i class="icon-heart"></i>
  </span>
  <span class="author">lnxpgn</span>
</div>

<div class="powered-by">
  Powered by <a class="theme-link" href="http://hexo.io">Hexo</a>
</div>

<div class="theme-info">
  Theme -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Mist
  </a>
</div>



      </div>
    </div>

    <div class="back-to-top"></div>
  </div>

  <script type="text/javascript" src="/vendors/jquery/index.js?v=2.1.3"></script>

  
  

  
  <script type="text/javascript" src="/vendors/fancybox/source/jquery.fancybox.pack.js"></script>
  <script type="text/javascript" src="/js/fancy-box.js?v=0.4.3"></script>


  <script type="text/javascript" src="/js/helpers.js?v=0.4.3"></script>
  

  <script type="text/javascript" src="/vendors/velocity/velocity.min.js"></script>
  <script type="text/javascript" src="/vendors/velocity/velocity.ui.min.js"></script>

  <script type="text/javascript" src="/js/motion_global.js?v=0.4.3" id="motion.global"></script>



  <script type="text/javascript" src="/js/search-toggle.js"></script>

  

  <script type="text/javascript">
    $(document).ready(function () {
      if (CONFIG.sidebar === 'always') {
        displaySidebar();
      }
    });
  </script>

  

  
  
  

  




  
  

</body>
</html>
